{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bb9559e-fb43-4e61-a791-0070daca36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Kaggle dataset: https://www.kaggle.com/c/titanic\n",
    "# Creds to pull kaggle dataset\n",
    "os.environ['KAGGLE_USERNAME'] = 'xxxxxxx'\n",
    "os.environ['KAGGLE_KEY'] = 'xxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40194865-d67e-4f7e-b6d1-69b812776cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanic.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  titanic.zip\n",
      "replace titanic_dataset/gender_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic\n",
    "!unzip titanic.zip -d titanic_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90e64873-df5a-4fd3-bff5-69e1cd63d8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fare', 'Fare*Class', 'Sex_female', 'Sex_male', 'Pclass_1', 'Pclass_2',\n",
       "       'Pclass_3', 'FamilySize', 'FarePerPerson', 'Title_Miss', 'Title_Mr',\n",
       "       'Title_Mrs', 'Title_Other', 'CabinLetter_A', 'CabinLetter_B',\n",
       "       'CabinLetter_C', 'CabinLetter_D', 'CabinLetter_E', 'CabinLetter_F',\n",
       "       'CabinLetter_G', 'CabinLetter_T', 'CabinLetter_U', 'AgeBin_Child',\n",
       "       'AgeBin_Teenager', 'AgeBin_Adult', 'AgeBin_Middle-aged',\n",
       "       'AgeBin_Senior', 'IsAlone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = pd.read_csv('titanic_dataset/train.csv')\n",
    "test_data = pd.read_csv('titanic_dataset/test.csv')\n",
    "\n",
    "# One-hot encoding for the categorical data\n",
    "def one_hot(data_set, columns):\n",
    "    return pd.get_dummies(data_set, columns=columns, dtype=np.float32)\n",
    "\n",
    "# Generate data about Mr, Mrs, Miss and no title\n",
    "def extract_title(name):\n",
    "    if 'Mr.' in name:\n",
    "        return 'Mr'\n",
    "    elif 'Mrs.' in name:\n",
    "        return 'Mrs'\n",
    "    elif 'Miss.' in name:\n",
    "        return 'Miss'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "train_data['Fare*Class'] = train_data['Fare'] * train_data['Pclass']\n",
    "test_data['Fare*Class'] = test_data['Fare'] * test_data['Pclass']\n",
    "\n",
    "train_data = one_hot(train_data, ['Sex', 'Pclass'])\n",
    "test_data = one_hot(test_data, ['Sex', 'Pclass'])\n",
    "\n",
    "train_data['Title'] = train_data['Name'].apply(extract_title)\n",
    "test_data['Title'] = test_data['Name'].apply(extract_title)\n",
    "\n",
    "# Generate family size by adding siblings, spouces and parent children\n",
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "\n",
    "# Cabin letter\n",
    "train_data['CabinLetter'] = train_data['Cabin'].apply(lambda x: x[0] if pd.notna(x) else 'U')\n",
    "test_data['CabinLetter'] = test_data['Cabin'].apply(lambda x: x[0] if pd.notna(x) else 'U')\n",
    "\n",
    "# Per person fare\n",
    "train_data['FarePerPerson'] = train_data['Fare'] / train_data['FamilySize']\n",
    "test_data['FarePerPerson'] = test_data['Fare'] / test_data['FamilySize']\n",
    "\n",
    "# Age bins to turn age number to buckets\n",
    "train_data['AgeBin'] = pd.cut(train_data['Age'], bins=[0, 10, 20, 40, 60, 80], labels=['Child', 'Teenager', 'Adult', 'Middle-aged', 'Senior'])\n",
    "test_data['AgeBin'] = pd.cut(test_data['Age'], bins=[0, 10, 20, 40, 60, 80], labels=['Child', 'Teenager', 'Adult', 'Middle-aged', 'Senior'])\n",
    "\n",
    "train_data = one_hot(train_data, ['Title', 'CabinLetter', 'AgeBin'])\n",
    "test_data = one_hot(test_data, ['Title', 'CabinLetter', 'AgeBin'])\n",
    "\n",
    "train_data['IsAlone'] = (train_data['FamilySize'] == 1).astype(int)\n",
    "test_data['IsAlone'] = (test_data['FamilySize'] == 1).astype(int)\n",
    "\n",
    "y = train_data['Survived']\n",
    "t_id = test_data['PassengerId']\n",
    "\n",
    "train_data = train_data.drop(columns=['PassengerId', 'Age', 'Name', 'SibSp', 'Parch', 'Cabin', 'Ticket', 'Survived', 'Embarked'])\n",
    "test_data = test_data.drop(columns=['PassengerId', 'Age', 'Name', 'SibSp', 'Parch', 'Cabin', 'Ticket', 'Embarked'])\n",
    "# This column never shows up in the test data\n",
    "test_data['CabinLetter_T'] = 0\n",
    "\n",
    "train_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfeb6f66-1cf2-4073-8eb7-099e985c4c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Fare*Class</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>FarePerPerson</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>...</th>\n",
       "      <th>CabinLetter_F</th>\n",
       "      <th>CabinLetter_G</th>\n",
       "      <th>CabinLetter_T</th>\n",
       "      <th>CabinLetter_U</th>\n",
       "      <th>AgeBin_Child</th>\n",
       "      <th>AgeBin_Teenager</th>\n",
       "      <th>AgeBin_Adult</th>\n",
       "      <th>AgeBin_Middle-aged</th>\n",
       "      <th>AgeBin_Senior</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.042453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.069568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.046406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fare  Fare*Class  Sex_female  Sex_male  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0  0.014151    0.042453         0.0       1.0       0.0       0.0       1.0   \n",
       "1  0.139136    0.139136         1.0       0.0       1.0       0.0       0.0   \n",
       "2  0.015469    0.046406         1.0       0.0       0.0       0.0       1.0   \n",
       "3  0.103644    0.103644         1.0       0.0       1.0       0.0       0.0   \n",
       "4  0.015713    0.047138         0.0       1.0       0.0       0.0       1.0   \n",
       "\n",
       "   FamilySize  FarePerPerson  Title_Miss  ...  CabinLetter_F  CabinLetter_G  \\\n",
       "0         0.1       0.007076         0.0  ...            0.0            0.0   \n",
       "1         0.1       0.069568         0.0  ...            0.0            0.0   \n",
       "2         0.0       0.015469         1.0  ...            0.0            0.0   \n",
       "3         0.1       0.051822         0.0  ...            0.0            0.0   \n",
       "4         0.0       0.015713         0.0  ...            0.0            0.0   \n",
       "\n",
       "   CabinLetter_T  CabinLetter_U  AgeBin_Child  AgeBin_Teenager  AgeBin_Adult  \\\n",
       "0            0.0            1.0           0.0              0.0           1.0   \n",
       "1            0.0            0.0           0.0              0.0           1.0   \n",
       "2            0.0            1.0           0.0              0.0           1.0   \n",
       "3            0.0            0.0           0.0              0.0           1.0   \n",
       "4            0.0            1.0           0.0              0.0           1.0   \n",
       "\n",
       "   AgeBin_Middle-aged  AgeBin_Senior  IsAlone  \n",
       "0                 0.0            0.0        0  \n",
       "1                 0.0            0.0        0  \n",
       "2                 0.0            0.0        1  \n",
       "3                 0.0            0.0        0  \n",
       "4                 0.0            0.0        1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Finally, we need to normalize the non-binary columns\n",
    "columns_to_normalize = ['Fare', 'FamilySize', 'FarePerPerson', 'Fare*Class']\n",
    "train_data[columns_to_normalize] = scaler.fit_transform(train_data[columns_to_normalize])\n",
    "test_data[columns_to_normalize] = scaler.fit_transform(test_data[columns_to_normalize])\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc63ddf3-55fa-4c54-91aa-0abb85b5c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_size = 550\n",
    "\n",
    "X_train, y_train = torch.tensor(train_data[:train_size].values, dtype=torch.float32), \\\n",
    "  torch.tensor(y[:train_size].values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val, y_val = torch.tensor(train_data[train_size:].values, dtype=torch.float32), \\\n",
    "  torch.tensor(y[train_size:].values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test = torch.tensor(test_data.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61284dce-2686-4f54-963d-5aa3c512f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 0.7992701530456543, Test Loss: 0.8099290728569031\n",
      "Epoch 1000, Training Loss: 0.7577621340751648, Test Loss: 0.7661786079406738\n",
      "Epoch 2000, Training Loss: 0.7267162799835205, Test Loss: 0.7328916192054749\n",
      "Epoch 3000, Training Loss: 0.7055034041404724, Test Loss: 0.7099096775054932\n",
      "Epoch 4000, Training Loss: 0.6904851198196411, Test Loss: 0.6940154433250427\n",
      "Epoch 5000, Training Loss: 0.6791715025901794, Test Loss: 0.6823642253875732\n",
      "Epoch 6000, Training Loss: 0.67035973072052, Test Loss: 0.6734592318534851\n",
      "Epoch 7000, Training Loss: 0.6632843613624573, Test Loss: 0.666422426700592\n",
      "Epoch 8000, Training Loss: 0.6574632525444031, Test Loss: 0.6607682704925537\n",
      "Epoch 9000, Training Loss: 0.6526130437850952, Test Loss: 0.6561776399612427\n",
      "Epoch 10000, Training Loss: 0.6485416293144226, Test Loss: 0.6523760557174683\n",
      "Epoch 11000, Training Loss: 0.6450958251953125, Test Loss: 0.6491701006889343\n",
      "Epoch 12000, Training Loss: 0.6421522498130798, Test Loss: 0.646439790725708\n",
      "Epoch 13000, Training Loss: 0.639616847038269, Test Loss: 0.6441083550453186\n",
      "Epoch 14000, Training Loss: 0.6374229788780212, Test Loss: 0.6421224474906921\n",
      "Epoch 15000, Training Loss: 0.63551926612854, Test Loss: 0.6404314637184143\n",
      "Epoch 16000, Training Loss: 0.6338604092597961, Test Loss: 0.6389857530593872\n",
      "Epoch 17000, Training Loss: 0.6324061751365662, Test Loss: 0.6377411484718323\n",
      "Epoch 18000, Training Loss: 0.6311230659484863, Test Loss: 0.6366561651229858\n",
      "Epoch 19000, Training Loss: 0.6299839615821838, Test Loss: 0.6357030868530273\n",
      "Epoch 20000, Training Loss: 0.6289684772491455, Test Loss: 0.6348705291748047\n",
      "Epoch 21000, Training Loss: 0.628059983253479, Test Loss: 0.6341568827629089\n",
      "Epoch 22000, Training Loss: 0.6272434592247009, Test Loss: 0.6335724592208862\n",
      "Epoch 23000, Training Loss: 0.6265048384666443, Test Loss: 0.6331322193145752\n",
      "Epoch 24000, Training Loss: 0.6258332133293152, Test Loss: 0.632796049118042\n",
      "Epoch 25000, Training Loss: 0.6252205967903137, Test Loss: 0.6325048208236694\n",
      "Epoch 26000, Training Loss: 0.6246606707572937, Test Loss: 0.6322323679924011\n",
      "Epoch 27000, Training Loss: 0.6241478323936462, Test Loss: 0.6319729685783386\n",
      "Epoch 28000, Training Loss: 0.6236767768859863, Test Loss: 0.631725013256073\n",
      "Epoch 29000, Training Loss: 0.6232430338859558, Test Loss: 0.6314826011657715\n",
      "Epoch 30000, Training Loss: 0.6228423714637756, Test Loss: 0.6312416791915894\n",
      "Epoch 31000, Training Loss: 0.6224716305732727, Test Loss: 0.6310058832168579\n",
      "Epoch 32000, Training Loss: 0.6221274733543396, Test Loss: 0.6307802796363831\n",
      "Epoch 33000, Training Loss: 0.6218075752258301, Test Loss: 0.6305670142173767\n",
      "Epoch 34000, Training Loss: 0.6215093731880188, Test Loss: 0.6303663849830627\n",
      "Epoch 35000, Training Loss: 0.6212306618690491, Test Loss: 0.6301781535148621\n",
      "Epoch 36000, Training Loss: 0.6209697723388672, Test Loss: 0.6300017833709717\n",
      "Epoch 37000, Training Loss: 0.6207250356674194, Test Loss: 0.6298370957374573\n",
      "Epoch 38000, Training Loss: 0.6204949021339417, Test Loss: 0.629683256149292\n",
      "Epoch 39000, Training Loss: 0.6202781200408936, Test Loss: 0.6295398473739624\n",
      "Epoch 40000, Training Loss: 0.6200735569000244, Test Loss: 0.6294062733650208\n",
      "Epoch 41000, Training Loss: 0.619880199432373, Test Loss: 0.629281759262085\n",
      "Epoch 42000, Training Loss: 0.6196973919868469, Test Loss: 0.6291659474372864\n",
      "Epoch 43000, Training Loss: 0.6195241212844849, Test Loss: 0.6290582418441772\n",
      "Epoch 44000, Training Loss: 0.6193596720695496, Test Loss: 0.6289582252502441\n",
      "Epoch 45000, Training Loss: 0.6192036867141724, Test Loss: 0.6288655400276184\n",
      "Epoch 46000, Training Loss: 0.6190551519393921, Test Loss: 0.6287801265716553\n",
      "Epoch 47000, Training Loss: 0.6189138293266296, Test Loss: 0.6287015080451965\n",
      "Epoch 48000, Training Loss: 0.6187789440155029, Test Loss: 0.6286293268203735\n",
      "Epoch 49000, Training Loss: 0.6186503171920776, Test Loss: 0.6285638213157654\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "n = len(X_train[0])\n",
    "\n",
    "model = nn.Linear(n, 1, bias=True)\n",
    "lr = 0.0001\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for t in range(50000):\n",
    "    y_pred = torch.sigmoid(model(X_train))\n",
    "\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    if t % 1000 == 0:\n",
    "        with torch.no_grad():\n",
    "            y_pred_test = torch.sigmoid(model(X_val))\n",
    "            test_loss = loss_fn(y_pred_test, y_val)\n",
    "            print(f\"Epoch {t}, Training Loss: {loss.item()}, Test Loss: {test_loss}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd9cf28-da2e-48d3-b3f3-79a11d7d613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try this on the test set and try submitting it\n",
    "\n",
    "predictions = torch.sigmoid(model(X_test))  # Assuming 'model' is your trained model and 'X_test' is your test data\n",
    "predictions = (predictions.squeeze() > 0.5).int()  # Convert to binary output\n",
    "\n",
    "# Create a DataFrame with the required structure\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': t_id,  # Replace with actual Passenger IDs from the test dataset\n",
    "    'Survived': predictions.numpy()\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba89bc-39f3-4d47-9b3a-66349631fb18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
